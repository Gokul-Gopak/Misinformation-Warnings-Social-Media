# Misinformation-Warnings-Social-Media

Misinformation has emerged as a critical challenge on social media platforms, particularly during pivotal events like elections. This study investigates the effectiveness of misinformation warnings on four major platforms—Facebook, Instagram, Threads, and Twitter/X—focusing on the lead-up to the 2024 U.S. Presidential Election. The primary research questions address how design features of warnings influence user trust and engagement, how perceptions of platform bias shape these responses, and the impact of political ideology and social media habits. Using a survey of 19 participants from Penn State University, we analyzed user interactions with static screenshots of misinformation posts accompanied by platform-specific warnings. Results revealed that Instagram's warnings were rated highest in clarity and effectiveness, while Threads and Twitter/X faced challenges with user trust and perceived bias. Our findings highlight the importance of transparency, context-rich warnings, and neutral designs in fostering trust and reducing misinformation engagement. Overall, this research contributes actionable insights for designing effective misinformation warnings and underscores the role of platform reputation in content moderation strategies
